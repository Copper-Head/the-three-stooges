{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation test of LK-C-Model\n",
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from blocks.model import Model\n",
    "from conllutil import CoNLLData\n",
    "from itertools import chain\n",
    "from network import *\n",
    "from numpy import array, load, save, zeros\n",
    "from os import path\n",
    "from pandas import factorize\n",
    "from random import randint\n",
    "from scipy.stats import pearsonr\n",
    "from theano import function\n",
    "from theano.tensor.sharedvar import SharedVariable\n",
    "from theano.tensor import matrix, TensorType\n",
    "from util import StateComputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALPHA = .05\n",
    "MODEL_FILE = './models/hdt/hdt-ncs-eos-np-35-7-1.pkl'\n",
    "IX_2_TOK_FILE = './data/hdt-ncs-eos-np-35-7-1_ix2tok.npy'\n",
    "HDT_DIR = '../datasets/hdt/hamburg-dependency-treebank-conll/'\n",
    "NP_FOLDER = './data/np'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ix2tok = load(IX_2_TOK_FILE).item()\n",
    "nt = Network(NetworkType.LSTM, input_dim=len(ix2tok))\n",
    "nt.set_parameters(MODEL_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model(nt.generator.generate(n_steps=nt.x.shape[0], batch_size=nt.x.shape[1]))\n",
    "param_dict = model.get_parameter_dict()\n",
    "init_state_0 = param_dict['/sequencegenerator/with_fake_attention/transition/layer#0.initial_state#0']\n",
    "init_state_1 = param_dict['/sequencegenerator/with_fake_attention/transition/layer#1.initial_state#1']\n",
    "init_state_2 = param_dict['/sequencegenerator/with_fake_attention/transition/layer#2.initial_state#2']\n",
    "init_cells_0 = param_dict['/sequencegenerator/with_fake_attention/transition/layer#0.initial_cells']\n",
    "init_cells_1 = param_dict['/sequencegenerator/with_fake_attention/transition/layer#1.initial_cells']\n",
    "init_cells_2 = param_dict['/sequencegenerator/with_fake_attention/transition/layer#2.initial_cells']\n",
    "reset_values = {\n",
    "    0: (init_state_0.get_value(), init_cells_0.get_value()),\n",
    "    1: (init_state_1.get_value(), init_cells_1.get_value()),\n",
    "    2: (init_state_2.get_value(), init_cells_2.get_value())\n",
    "}\n",
    "gen_func = model.get_theano_function(allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tok2ix = {v: k for k, v in ix2tok.items()}\n",
    "sc = StateComputer(nt.cost_model, tok2ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before we continue ... save the model in a lightweight format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save(path.join(NP_FOLDER, 'param_dict.npy'), array(param_dict))\n",
    "#for k in param_dict:\n",
    "#    save(path.join(NP_FOLDER, k.replace('/', '-')), param_dict[k].get_value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reset_generator():\n",
    "    init_state_0 = reset_values[0][0]\n",
    "    init_cells_0 = reset_values[0][1]\n",
    "    init_state_1 = reset_values[1][0]\n",
    "    init_cells_1 = reset_values[1][1]\n",
    "    init_state_2 = reset_values[2][0]\n",
    "    init_cells_2 = reset_values[2][1]\n",
    "    \n",
    "def init_zero():\n",
    "    # note sure this is always a good idea\n",
    "    d = init_state_0.get_value().shape[0]\n",
    "    dt = 'float32'\n",
    "    init_state_0.set_value(zeros(d, dtype=dt))\n",
    "    init_cells_0.set_value(zeros(d, dtype=dt))\n",
    "    init_state_1.set_value(zeros(d, dtype=dt))\n",
    "    init_cells_1.set_value(zeros(d, dtype=dt))\n",
    "    init_state_2.set_value(zeros(d, dtype=dt))\n",
    "    init_cells_2.set_value(zeros(d, dtype=dt))\n",
    "    \n",
    "def generate_sequence(start, reset_func):\n",
    "    \n",
    "    seq = [start]\n",
    "    ix = array([[tok2ix[start]]])\n",
    "    while not seq[-1] == '<EOS>':\n",
    "        state_0, cells_0, state_1, cells_1, state_2, cells_2, ix, costs = gen_func(ix)\n",
    "        init_state_0.set_value(state_0[0][0])\n",
    "        init_cells_0.set_value(cells_0[0][0])\n",
    "        init_state_1.set_value(state_1[0][0])\n",
    "        init_cells_1.set_value(cells_1[0][0])\n",
    "        init_state_2.set_value(state_2[0][0])\n",
    "        init_cells_2.set_value(cells_2[0][0])\n",
    "        seq.append(ix2tok[ix[0][0]])\n",
    "    \n",
    "    reset_func()\n",
    "    \n",
    "    return ' '.join(seq[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(generate_sequence('ein', reset_generator))  # good results 500 - 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15378268, -0.19670351, -0.16562188,  0.03126331, -0.06216872,\n",
       "       -0.40889442, -0.54963213, -0.11671217, -0.12459658, -0.35418853,\n",
       "       -0.95723981, -0.39901543], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_seq[1, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check correlations with POS\n",
    "## Step 1: Read all sentences from PART_A and store activations\n",
    "\n",
    "__comment:__  Only part A is used, since this one's annotations are handmade and checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eos_ix = tok2ix['<EOS>']\n",
    "cd = CoNLLData(HDT_DIR, ['part_A.conll'], tok2ix, word_transform=str.lower, lazy_loading=True, min_len=7, max_len=35)\n",
    "sentences_ix = [[tok2ix[seq[i]] for i in range(len(seq))] + [eos_ix] for seq in cd.wordsequences()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cell_name = sc.state_var_names[2]\n",
    "activations = []\n",
    "# for testing purposes only read one sequence, try again later with more\n",
    "activations.append(sc.read_single_sequence(sentences_ix[0])[cell_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlate for each pos tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_correlations = {}\n",
    "tagset = set(chain(*cd.possequences()))\n",
    "for tag in tagset:\n",
    "    pos_correlations[tag] = []\n",
    "    for i in range(len(activations)):    \n",
    "        act_seq = activations[i].transpose()\n",
    "        pos_seq = factorize(cd.possequences()[0])[0]\n",
    "        correls = []\n",
    "        for r in range(act_seq.shape[0]):\n",
    "            crl = pearsonr(act_seq[r, 1:], pos_seq)\n",
    "            correls.append(crl[0] if crl[1] < ALPHA else .0)\n",
    "        pos_correlations[tag].append(correls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
